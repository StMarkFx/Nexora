# Nexora Voice Assistant ğŸ™ï¸

Nexora is a **voice-controlled AI assistant** that can browse files, summarize text, answer questions, and even control apps. Built with **DeepSeek** (local LLM), **Whisper** (speech-to-text), and **Coqui TTS** (text-to-speech), Nexora is like having your own Jarvis!


## Features âœ¨

- **Voice Interaction**: Speak commands and get voice responses.
- **Text Processing**: Answer questions, summarize text, and execute commands using **DeepSeek**.
- **API Integrations**:
  - **NewsAPI**: Fetch news headlines.
  - **OpenWeatherMap**: Get weather updates.
  - **Google Calendar**: Manage reminders and events.
- **Browser Automation**: Perform web searches and automate tasks using **Selenium/Playwright**.
- **Advanced Features**:
  - Reminders and alarms.
  - Email integration (Gmail API).
  - System monitoring (CPU, RAM usage).


## Tech Stack ğŸ› ï¸

- **LLM**: DeepSeek (local)
- **Speech-to-Text**: OpenAI Whisper
- **Text-to-Speech**: Coqui TTS
- **APIs**: NewsAPI, OpenWeatherMap, Google Calendar API
- **Browser Automation**: Selenium/Playwright
- **Programming Language**: Python
- **Web Interface**: Streamlit


## Installation ğŸš€

### Prerequisites
- Python 3.8 or higher
- Microphone (for voice input)

### Steps
1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/nexora-voice-assistant.git
   cd nexora-voice-assistant
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Download and set up models:
   - **DeepSeek**: Place model files in `models/deepseek/`.
   - **Whisper**: Place model files in `models/whisper/`.
   - **Coqui TTS**: Place model files in `models/coqui_tts/`.

4. Configure API keys:
   - Create a `config/api_keys.json` file:
     ```json
     {
       "newsapi": "YOUR_NEWSAPI_KEY",
       "openweathermap": "YOUR_OPENWEATHERMAP_KEY",
       "google_calendar": "YOUR_GOOGLE_CALENDAR_CREDENTIALS"
     }
     ```

---

## Usage ğŸ¯

### Running the Assistant
1. Start the Streamlit interface:
   ```bash
   streamlit run main.py
   ```

2. Use the interface:
   - Click **"Record Voice Command"** to speak your command.
   - Wait for Nexora to process your command and respond.

### Example Commands
- **Weather**: "Whatâ€™s the weather in New York?"
- **News**: "What are the latest news headlines?"
- **Reminders**: "Remind me to call John at 3 PM."
- **Web Search**: "Search for AI news on Google."


## Project Structure ğŸ“‚
```
nexora-voice-assistant/
â”œâ”€â”€ README.md                       # Project documentation
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ main.py                         # Entry point for the voice assistant (Streamlit)
â”œâ”€â”€ config/                         # Configuration files
â”‚   â”œâ”€â”€ api_keys.json               # Store API keys securely
â”‚   â””â”€â”€ settings.json               # User preferences and settings
â”œâ”€â”€ models/                         # Local models (DeepSeek, Whisper, Coqui TTS)
â”‚   â”œâ”€â”€ deepseek/                   # DeepSeek model files
â”‚   â”œâ”€â”€ whisper/                    # Whisper model files
â”‚   â””â”€â”€ coqui_tts/                  # Coqui TTS model files
â”œâ”€â”€ src/                            # Source code
â”‚   â”œâ”€â”€ stt/                        # Speech-to-text module
â”‚   â”œâ”€â”€ tts/                        # Text-to-speech module
â”‚   â”œâ”€â”€ llm/                        # Language model module
â”‚   â”œâ”€â”€ api/                        # API integrations
â”‚   â”œâ”€â”€ browser/                    # Browser automation
â”‚   â”œâ”€â”€ utils/                      # Utility functions
â”‚   â””â”€â”€ core/                       # Core functionality
â”œâ”€â”€ tests/                          # Unit and integration tests
â”œâ”€â”€ logs/                           # Log files for debugging
â”œâ”€â”€ assets/                         # Static assets (icons, sounds)
â””â”€â”€ scripts/                        # Helper scripts (setup, deployment)
```


## Error Handling ğŸ›‘

Nexora includes **robust error handling** for:
- **No speech detected** during recording.
- **API failures** (e.g., Weather API or News API is down).
- **Invalid user commands**.
- **File I/O errors** (e.g., unable to save or read audio files).
- **Microphone access issues**.


## Contributing ğŸ¤

Contributions are welcome! Hereâ€™s how you can help:
1. Fork the repository.
2. Create a new branch:
   ```bash
   git checkout -b feature/your-feature-name
   ```
3. Commit your changes:
   ```bash
   git commit -m "Add your feature"
   ```
4. Push to the branch:
   ```bash
   git push origin feature/your-feature-name
   ```
5. Open a pull request.


## License ğŸ“œ

This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.


## Acknowledgments ğŸ™

- **DeepSeek**: For the local LLM.
- **OpenAI Whisper**: For speech-to-text.
- **Coqui TTS**: For text-to-speech.
- **Streamlit**: For the web interface.


## Contact ğŸ“§

For questions or feedback, reach out to:
- **Name**: [St. Mark Adebayo](your.email@example.com)
- **LinkedIn**: [St. Mark Adebayo](https://www.linkedin.com/in/stmarkadebayo)
- **GitHub**: [yourusername](https://github.com/yourusername)

